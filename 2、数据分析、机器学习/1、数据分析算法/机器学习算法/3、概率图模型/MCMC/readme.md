# `MCMC 马尔科夫链蒙特卡罗方法`

## `一、MCMC 引入：`

* `1、`最早的蒙特卡罗方法都是为了`求解一些不太好求解的求和或者积分问题`。比如积分：

    $$\theta=\int_a^bf(x)dx $$

    <font color='orange'>如果我们很难求解出 $f(x)$ 的原函数</font>，那么这个积分比较难求解。当然我们可以通过蒙特卡罗方法来模拟求解近似值。假设我们函数图像如下图:

    <div align=center><img height=300 src="./static/MCMC引入.jpg"/></div>

    则一个简单的近似求解方法是在 $[a,b]$ 之间随机的采样一个点。比如 $x_0$ ,然后用$f(x_0)$代表在 $[a,b]$ 区间上所有的 $f(x)$ 的值。那么上面的定积分的近似求解为:

    $$ (b−a)f(x_0)$$


    用一个值代表$[a,b]$区间上所有的$f(x)$的值，这个假设太粗糙。<font color='orange'>那么我们可以采样$[a,b]$区间的n个值：$x_0,x_1,...x_{n−1}$,用它们的均值来代表$[a,b]$区间上所有的$f(x)$的值。</font>这样我们上面的定积分的近似求解为:

    $$\frac{b-a}{b}\sum\limits_{i=0}^{n-1}f(x_i)$$

    虽然上面的方法可以一定程度上求解出近似的解，`但是它隐含了一个假定，即x在[a,b]之间是均匀分布的`，`而绝大部分情况，x在[a,b]之间不是均匀分布的`。如果我们用上面的方法，则模拟求出的结果很可能和真实值相差甚远。

* `2、`如果我们可以得到 $x$ 在 $[a,b]$ 的概率分布函数 $p(x)$ ，那么我们的定积分求和可以这样进行：

    $$\theta = \int_a^b f(x)dx = \int_a^b \frac{f(x)}{p(x)}p(x)dx \approx \frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}$$

    最后一步转换：由于 <font color='orange'>$\int_a^b \frac{f(x)}{p(x)}p(x)dx$ 可以看做是 $\frac{f(x)}{p(x)}$ 基于概率分布 $p(x)$ 的期望，</font>那么我们可以用期望的方法来求这个式子的值。
    
    <font color='orange'>而计算期望的一个近似方法是取 $\frac{f(x)}{p(x)}$ 的若干个基于分布 $p(x)$ 的采样点，然后求平均值得到。</font>__`(大数定理)`__

* `补充：`这里 $p(x)$的确不是均匀分布,如果没有这个分母，那就是我们假定了 $f(x)$ 是均匀分布。$f(x)$ 不均匀分布的时候在 $a-b$ 区间上的积分应该是：
    $$\int_a^b f(x)dx \ \ \ \ 而不是  \ \  \ \ \int_a^b f(x)p(x)dx \ \  \ \ 后面这个式子是 \ \  f(x) \ \ 的期望$$


### `概率分布的采样：`

* __`采样的引入 (为什么要进行采样的关键原因)：`__ 蒙特卡罗方法的关键是得到 $x$ 的概率分布。<font color='orange'>如果求出了 $x$ 的概率分布，我们可以基于概率分布去采样基于这个概率分布的 $n$ 个 $x$ 的样本集</font>，带入蒙特卡罗求和的式子即可求解。
  
  <font color='orange'>但是如何基于概率分布去采样基于这个概率分布的 $n$ 个 $x$ 的样本集？</font> 一些常见的分布可以通过 `均匀分布` 得到的采样样本进行转化，但是很多时候，`我们的x概率分布不是常见的分布`，那么此时`采样就很困难`。




### `MCMC 补充：`

* 蒙特卡罗方法又称统计模拟法、随机抽样技术，是一种随机模拟方法，以概率和统计理论方法为基础的一种计算方法，是使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。将所求解的问题同一定的概率模型相联系，用电子计算机实现统计模拟或，以获得问题的近似解。为象征性地表明这一方法的概率统计特征，故借用赌城蒙特卡罗命名。

* `MCMC的目的是这样：`事先知道要采样的真实分布是什么（即平稳分布），但很难在现实中对该分布进行采样，所以利用马尔可夫链的性质，通过 `M_H` 采样获得满足平稳分布的样本点。然后这些采样点本身就就刻画出了了真实的概率分布是怎么样的。

* `MCMC` 只是为了解决 `分布已知` ，但是 `难采样` 的问题。如果分布不知，那么 `MCMC` 是无能为力的。


## `二、常用的采样方法：`

* `1、接受-拒绝采样`

* `2、重要性采样`


### `接受 - 拒绝采样过程：`


* 当 `cdf(累积分布函数)` 很难求解的时候，我们就不能通过求 `cdf(累积分布函数)` 的 `反函数` 来求得样本 `xi`。那么此时我们可以通过构造一个近似 `f(x)` 的分布 `q(x)` 来对 `f(x)` 进行近似，达到接近 `f(x)` 的目的，这个 `q(x)` 必须满足 `m * q(x) > f(x) `这个条件。

    <div align=center><img  src="./static/引出接受拒绝采样1.jpg"/></div>

* 如何对样本 `x` 进行 `接受` 和 `拒绝`：


    <div align=center><img  src="./static/接受和拒绝条件.jpg"/></div>

    * 因为 U 是随机取的，那我们采到的样本即使满足这个条件 $f(x) / m*q(x) >= U$ 也可能不在 $f(x)$ 分布中的，这里就是一种采样的近似模拟，不是 100% 的等价于采样原分布。但是这个近似的分布很多时候也可以满足我们的需求。



### `接受拒绝 - 采样存在的问题：`

* 1）对于一些二维分布 `p(x,y)`，有时候我们只能得到条件分布 `p(x|y)` 和 `p(y|x)` 和,却很难得到二维分布 `p(x,y)` 一般形式，这时我们无法用 `接受-拒绝采样` 得到其样本集。

* 2）对于一些高维的复杂非常见分布 `p(x1,x2,...,xn)` ，我们要找到一个合适的 `q(x)` 和 `k` 非常困难。


* 补充：`为什么当 p(x) 概率分布很复杂的时候，很难进行采样，而需要使用比如：接受拒绝-采样、重参数采样等方法？`



    <div align=center><img width="600" height="340" src="./static/引出接受拒绝采样2.jpg"/></div>

### `重要性采样：`

* `重要性采样（Importance Sampling）：`https://zhuanlan.zhihu.com/p/41217212

* `蒙特卡洛采样中（重要采样），为什么从Px中采样困难？：`https://www.zhihu.com/question/313194059
  

### <font color='red'>两个采样方法的缺点：</font>

* 但是两个采样存在着问题，因为需要让 `提议分布q(x)` 尽可能的和 `真实的概率分布p(x)` 接近，因为本来的 `p(x)` 就很复杂，所以想要找到这样的一个 `提议分布q(x)` 非常困难。
    
* 并且还需要 `提议分布q（x）` 足够简单。

## `三、MCMC 采样：`

### `马尔可夫链`

* 在蒙特卡罗方法中，我们采集大量的样本，构造一个合适的概率模型，对这个模型进行大量的采样和统计实验，使它的某些统计参量正好是待求问题的解。但是，我们需要大量采样，虽然我们有拒绝-接受采样和重采样技术，但是依旧面临采样困难的问题。

* 马尔科夫链就是帮助找到这些复杂概率分布的对应的采样样本集的白衣骑士。


### `为什么可以通过 马尔科夫链 来进行采样：`
  
* ` 马尔科夫链模型的状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关。这是一个非常好的性质，也就是说，`如果我们得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则我们可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本。`

    这个性质不光对我们上面的状态转移矩阵有效，对于绝大多数的其他的马尔科夫链模型的状态转移矩阵也有效。同时不光是离散状态，连续状态时也成立。

* 假设我们任意初始的概率分布是  $π_0(x)$, 经过第一轮马尔科夫链状态转移后的概率分布是 $π_1(x)$ ，。。。第i轮的概率分布是 $π_i(x)$ 。假设经过n轮后马尔科夫链收敛到我们的平稳分布  $π(x)$ ，即：

    $$π_n(x)=π_{n+1}(x)=π_{n+2}(x)=...=π(x)$$

  对于每个分布 $π_i(x)$，我们有：

    $$π_i(x)=π_{i−1}(x)P=π_{i−2}(x)P_2=π_0(x)P_i$$



  现在我们可以开始采样了，首先，初始任意简单概率分布比如 `高斯分布π0(x)` 采样得到 `状态值x0` ，基于 `条件概率分布P(x|x0)` 采样 `状态值x1` ，一直进行下去，当状态转移进行到一定的次数时，比如到 `n次` 时，我们认为此时的 `采样集(xn,xn+1,xn+2,...)` 即是符合我们的`平稳分布` 的 `对应样本集` ，可以用来做蒙特卡罗模拟求和了。
  
### `MCMC 采样过程：`

* 在 `MCMC` 采样中的难点是如何得到一个状态转移矩阵 $P$。求解 $P$ 可以通过马尔科夫的细致平稳条件计算得到，定义如下：

    如果非周期马尔科夫链的状态转移矩阵P和概率分布 $π(x)$ 对于所有的 $i,j$ 满足：
    
    $$π(i)P(i,j)=π(j)P(j,i)$$
    则称概率分布 $π(x)$ 是状态转移矩阵 $P$ 的平稳分布。

* 虽然有这种方法，但是计算 状态转移矩阵 $P$  还是十分困难，也就是给定任意一个状态转移矩阵Q，，此时有可能不满足`细致平稳条件(可逆马尔科夫链)`：

    $$π(i)Q(i,j)≠π(j)Q(j,i)$$

* 当不满足细致平稳条件时，此时的转移矩阵 $Q$ 不等于上面讲的真正的状态转移矩阵 $P$，但是可以通过引入一个接受率，来达到真实马尔科夫状态转移矩阵的效果( 引入一个 $α(i,j)$ )：

    $$π(i)Q(i,j)α(i,j)=π(j)Q(j,i)α(j,i)$$

    其中满足：

    $$α(i,j)=π(j)Q(j,i)$$
    
    $$α(j,i)=π(i)Q(i,j)$$

    这样，我们就得到了我们的分布 $π(x)$ 对应的马尔科夫链状态转移矩阵 $P$ ，满足：

    $$P(i,j)=Q(i,j)α(i,j)$$

* `MCMC 的采样过程：`

    1）输入我们任意选定的马尔科夫链状态转移矩阵 $Q$ ，平稳分布 $π(x)$ ，设定状态转移次数阈值 $n_1$，需要的样本个数 $n_2$。

    2）从任意简单概率分布采样得到初始状态值 $x_0$
    
    3）$for \ t=0 \ \ to \ \ n_1+n_2−1:$
    
    *    a) 从条件概率分布 $Q(x|x_t)$ 中采样得到样本 $x_∗$
    
    *    b) 从均匀分布采样 $u∼uniform[0,1]$
    
    *    c) 如果 $u<α(x_t,x_∗)=π(x_∗)Q(x_∗,x_t)$ , 则接受转移 $x_t→x_∗$，即 $x_{t+1}=x_∗$
    
    *    d) 否则不接受转移，即 $x_{t+1}=x_t$
        
    样本集 $(x_{n1},x_{n1+1},...,x_{n1+n2−1})$ 即为我们需要的平稳分布对应的样本集。

* 上面这个过程基本上就是 `MCMC` 采样的 `完整采样理论` 了，但是这个采样算法还是比较难在实际中应用,由于 $α(x_t,x_∗)$ 可能非常的小，比如 $0.1$ ，导致我们大部分的采样值都被拒绝转移，采样效率很低。有可能我们采样了上百万次马尔可夫链还没有收敛，也就是上面这个 $n_1$ 要非常非常的大,为了解决这个问题，于是有了 `MH采样`。

### `MCMC 采样举例说明：`

* <font color='gren'>当我们知道真正的状态转移矩阵 $P$ 时有：</font>

  * 关于` “离散分布是用采样时对应的分布律去乘以条件概率转移矩阵P，得到新的分布。”`这个是理论上可以得到最终 `平稳分布` 的方法。

    `实际采样` 的时候，是 `基于转移矩阵中P` 的 `对应一行` 的 `转移概率` ，来 `采样` 得到新的离散样本，<font color='orange'>等价于你基于隐含的那个真正的想采样的pi来采样。</font>

  * 使用股市案例：

      <div align=center><img src="./static/MCMC案例1.jpg"/></div>

      `t=0` 的时候，基于 `初始分布 [0.3,0.4,0.3] 采样` ，假设我们采样到了最高概率的第二个离散值，也就是 $x_0 =熊市$。然后我们在马尔科夫转移矩阵中找到熊市对应的条件概率分布，也就是 `[0.15,0.8,0.05]` ， 此时我们 `基于这个概率分布` 来进行`采样` $x_1$，最有可能采样到的还是熊市。 假设我们这次运气好采样到了横盘，即 $x_1= 横盘$ ，然后就找 `横盘对应的条件概率分布`，也就是 `[0.25,0.25,0.5]` ，基于这个概率分布采样 $x_2$，以此类推。
    
* <font color='gren'>当取任意的的状态转移矩阵 $Q$ 时有：</font>

  * 在马尔科夫链(状态转移矩阵为 $Q$ )中随机游走，当达到平稳分布时，每个时刻随机游走一次，就可以得到一个样本，这时，以一定的接受率 `α` 获得，通过一定的接受-拒绝概率得到目标转移矩阵 $P$ 。


## `HM采样`

* `M-H的确没有选择的函数比目标分布要大的要求，因为他的采样方式是通过马尔科夫链转移，而不是直接的拒绝采样。`关于选择转移矩阵技巧，如果是离散的转移矩阵，其实随机选择一个也行，关于条件概率，则一般喜欢使用正态分布，因为对于的算法库API功能丰富，方便采样。



* 首先跟拒绝算法类似，MH也是通过熟悉的分布去采样一个复杂的分布，但区别在于两点:

  * （1）MH中自定义的分布与原分布不一定相似

  * （2）接受率的定义不同，MH中的接受率是（某一状态）与（这一状态通过自定义分布的条件概率产生的下一个状态）在原分布中概率的大小的比值；而拒绝采样的接受率是在（自定义分布）中根据均匀分布产生一个点，然后看他落在（自定义分布）还是（原分布）的概率中。

* 需要确定的一点：

  * （1）原分布与自定义分布的定义域需要一致，这样才能用自定义分布采样出符合原分布定义域的样本

* 有可能导致的问题：

  * （1）如果自定义分布与原分布相差很多，则在某一区间内，可能自定义分布产生大量样本，但是原分布中只存在少量。此时只能用接受率，拒绝大量的样本。反之亦然。这就是效率低下的原因。


### `MH 采样过程：`


* `步骤：`

    <div align=center><img src="./static/MH采样过程.jpg"/></div>

* `1`、给定任意 `转移矩阵Q` 和 `平稳分布 π(x)`

* `2`、在 `t = 0` ，随机产生一个 `初始状态 x0`。

* `3~`、`t=0` 的时候，基于 `初始分布[0.3,0.4,0.3]` 采样，假设我们采样到了最高概率的第二个离散值，也就是 `x0=熊市` 。然后我们在马尔科夫转移矩阵中找到熊市对应的条件概率分布，也就是 `[0.15,0.8,0.05]` ， 此时我们基于这个概率分布来进行 `采样x1` ，最有可能采样到的还是熊市。 假设我们这次运气好采样到了横盘，即 `x1= 横盘` ，然后就找横盘对应的条件概率分布，也就是 `[0.25,0.25,0.5]` ，基于这个概率分布 `采样x2`，以此类推。

### `案例:`

* 以股市为例的马尔科夫模型举例：

    <div align=center><img src="./static/MH采样案例.jpg"/></div>


* `1、第一次循环：`

    *   比如随机获取到 `初始状态 x0 = 熊市` ，熊市为第二个状态，对应的 `状态转移矩阵为[0.15,0.8,0.05]` ,然后基于这个概率分布采样，有80%的概率采到自己，比如比较幸运，采到了 `x1 = 横盘` 这个样本，那么接下来计算 ` α` 。

        `(熊市概率) π(j) = 目标分布 P(熊市)  ，Q(j,i) = 0.05`

        `(横盘概率) π(i) = 目标分布 P(横盘) ,   Q(i,j) = 0.25 `

        那么 `α  = P(熊市) * 0.05 /(P(横盘)*0.25) ≈ p`，那么这个 `p` 就是 `α` 的值。

        然后在 `均匀分布` 中随机取一个 `u` 。

        比较 `u < α` ，如果满足则接受 `横盘` 这个采样，`x1 = 横盘` 。

* `2、第二次循环`,同理，如果采到了 `牛市` 但是不接受样本，则仍然保留之前的样本为新的样本即 `x2 = 横盘`。

* `最终：`这样就能将样本的分布律收敛到平稳分布一样了，但是其中关于接受拒绝采样的措施感觉还是太随机了，这样也有可能造成即使符合目标分布也被拒绝，和不符合目标分布也被接受 的情况，不过基于大数定理，最后采样的结果还是很接近目标分布的，所以无伤大雅。（我们的目标是采样的样本分布整体符合目标分布，而不是单个样本符合目标分布。所以在中间阶段，部分样本的拒绝和接受不影响整体结果。）


* `平稳分布的作用：`目标的平稳分布和真实分布完全一样的。所以谈不上平稳分布的作用，引入平稳分布主要是为了阐述 MCMC 采样理论的正确性。

* `需要注意的是：`

    * 定义的平稳分布是最终目标分布，就是我们真正的 `马尔科夫转移矩阵 P 的平稳分布` ，但是不是我们 `随机给的马尔科夫转移矩阵 Q 的平稳分布`，需要`基于 Q 做 MCMC 采样才能得到 P 对应平稳分布的样本`。


    * 也就是：我们随机取的马尔科夫转移矩阵 $Q$ 他的平稳分布不是目标分布 $P(x)$ 的分布，需要借助拒绝采样的思想，才能使最终分布为 $p(x)$ 。

        在步骤1中写到：1）输入我们任意选定的马尔科夫链状态转移矩阵 $Q$，平稳分布 $π(x)$ ，设定状态转移次数阈值 $n_1$ ，需要的样本个数$n_2$。

        因为起先的状态转移矩阵 $P$ 比较难直接得到，所以他的平稳分布也难通过它直接计算，所以就直接设置 norm_dist_prob 为最终的目标分布就行了，因为他们两个相同，这其实也等同于步骤1中设置的平稳分布π(x) 这个环节。

## `吉布斯采样`

* 吉布斯采样是一维一维的进行采样，当采i维的时候，固定其他的 i-1 维。

* 比如，现在对概率分布 π(x,y) 进行采样：


    <div align=center><img src="./static/吉布斯采样/图.jpg"/></div>


* 假设现在在概率分布 π(x,y) 中随意取两点 A(x1,y1) 和 B(x1,y2)，则有公式：

    <div align=center><img src="./static/吉布斯采样/1.jpg"/></div>

* 如果在 π(A) 左右两边分别乘以 π(y2|x1),则有：

    <div align=center><img src="./static/吉布斯采样/2.jpg"/></div>

* 则形成了一个 `细致平衡条件 π(i)P(i,j) = π(j)P(j,i)`

    <div align=center><img src="./static/吉布斯采样/3.jpg"/></div>

* `既然满足细致平衡条件，那么就可以使用马尔科夫链进行采样`


* 接下来我们就可以将 `π(y2|x1) 称为状态转移概率 P(A -> B)`,则有：

    <div align=center><img src="./static/吉布斯采样/4.jpg"/></div>

推广：

* 同样，如果有一个点 C(x2,y1) ,我们同样可以使用刚刚的方法，则有：

    <div align=center><img src="./static/吉布斯采样/5.jpg"/></div>

* 意味着：

    <div align=center><img src="./static/吉布斯采样/6.jpg"/></div>


和 MH 不一样的地方在于：

* MH 的公式为：

    <div align=center><img src="./static/吉布斯采样/MH细致平衡条件.jpg"/></div>

    在 MH 中并不是所有的样本都会被接受，他是会根据 α 来做一定概率上的拒绝的。

* Gibbs 采样：

    吉布斯采样不一样，他的 `P(A -> B) = π(y2|x1)`，其中这个 `π(y2|x1)` 是已知的，这意味着这他不拒绝，会接受全部样本。

但是 `Gibbs 采样` 还是存在缺陷，`只允许在平行坐标轴方向进行采样`(要么平行 X 轴采样，要么平行 Y 轴采样)：

* 比如现在有一点 D ，已知 A B 的情况下不能对它采样，因为对于 A 和 B 来说 D 的 x坐标 或者 y坐标 和它们没有一个一样。

    <div align=center><img src="./static/吉布斯采样/图2.jpg"/></div>

    <div align=center><img src="./static/吉布斯采样/7.jpg"/></div>

### `Gibbs 采样的基本步骤：`



<div align=center><img src="./static/吉布斯采样/Gibbs采样步骤.jpg"/></div>


## 参考：


* `你一定从未看过如此通俗易懂的马尔科夫链蒙特卡罗方法(MCMC)解读(上)：`https://zhuanlan.zhihu.com/p/250146007


* `你一定从未看过如此通俗易懂的马尔科夫链蒙特卡罗方法(MCMC)解读(下): `https://zhuanlan.zhihu.com/p/253784711

* `MCMC(一)蒙特卡罗方法：`https://www.cnblogs.com/pinard/p/6625739.html


* `MCMC(三)MCMC采样和M-H采样: `https://www.cnblogs.com/pinard/p/6638955.html#!comments


* `MCMC(四)Gibbs采样:` https://www.cnblogs.com/pinard/p/6645766.html


* `Video - 蒙特卡洛（Monte Carlo, MCMC）方法的原理和应用: `https://www.bilibili.com/video/BV17D4y1o7J2


* `Video - Gibbs采样:` https://www.bilibili.com/video/BV1ey4y1t7Jb



## 相关疑问：

问：

    for t=0 to n1+n2−1:
    a) 从条件概率分布Q(x|xt)中采样得到样本x∗
    b) 从均匀分布采样u∼uniform[0,1]
    c) 如果u<α(xt,x∗)=π(x∗)Q(x∗,xt), 则接受转移xt→x∗，即xt+1=x∗
    d) 否则不接受转移，t=max(t−1,0)

    u是[0,1]上的随机数，是否意味着c)步中拒绝和接受也是随机的？因为u<α由u的随机性决定。

答：

    是的，接受和拒绝满足随机性，类似之前讲到的接受-拒绝采样。


<div align=center><img src="./static/problem/1.jpg"/></div>

<div align=center><img  src="./static/problem/2.jpg"/></div>

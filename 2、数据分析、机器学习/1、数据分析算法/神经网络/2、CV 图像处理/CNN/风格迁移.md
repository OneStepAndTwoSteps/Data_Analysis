# `图像风格迁移`

* 图像风格迁移主要任务是将 `风格图像` 的风格迁移到 `内容图像` 上，使得内容图像也具有一定的风格。


## `固定风格固定内容的普通风格迁移：`

* `One obvious caveat of this approach is that it is slow. It takes several optimization iterations to tune the random image such that it adapts to the content and style of two different reference images。`

### `普通风格迁移简介：`

* `固定风格固定内容的普通风格迁移：`也称为`普通图像风格迁移方法`，也是最早的记忆深度卷积神经网络的图像风格迁移方法。普通风格迁移过程中，把生成图片的过程当做一个“训练”的过程。每生成一张图片，都相当于要训练一次模型，过程很耗时。

    其中的思想是把 `图像` 当成是一个可训练的变量，通过不断优化图片的像素值，降低其与 `内容图片` 的差异，降低其与 `风格图片` 的风格差异，通过卷积网络的多次迭代，能够生成一幅具有特定风格的图像，并且 `图像的内容` 与 `内容图片` 中的内容一致，`生成的图片风格` 也和 `风格图片` 中的风格一致。

    <div align=center><img height =400 src="./static/风格迁移/风格迁移1.jpg"/></div>


    上图是基于 `VGG16` 网络中卷积层的图像风格迁移，左图的 $\vec{a}$ 表示风格图像，右边的 $\vec{p}$ 表示输入的内容图像，中间的图像 $\vec{x}$ 表示由`随机噪声`生成的图像风格迁移后的图像，图中的两个 $Loss$ ，$Loss_{style}$ 和 $Loss_{content}$ ，分别表示图像的风格损失和内容损失，总的损失为 $\alpha Loss_{content} + \beta Loss_{style}$ , `alpha` 和 `beta` 分别是内容损失的权重和风格损失的权重。



* 在 `深度卷积神经网络` 中 `接近输入层` 的 `Feature Map` 包含更多的图像的 `纹理` 等细节信息，而 `接近输出层` 的 `Feature Map` 则包含更多的 `内容信息` 。也就是使用 `深层次` 的卷积计算得到的特征映射能够 `较好地表示图像内容` ，而 `较浅层次` 的卷积计算得到的特征映射 `能够较好的表示图像的风格` 。基于这种思想就可以通过不同卷积层的特征映射来度量目标图像在风格上和风格图像的差异，以及在内容上和内容图片的差异。

### `内容表示损失计算：`

* 两个图像内容的相似度主要通过度量经过 `VGG16` 的 `conv4_2` 层上的特征映射的相似度作为图像内容的损失，损失函数如下：

    假设其层数为 $l$， $N_l$ 是 `Feature Map` 的数量，也就是通道数， $M_l$  是 `Feature Map` 的像素点的个数。那么我们得到 `Feature Map` $F^l$  可以表示为 $F^l \in R^{N_l*M_l}$  ， $F^l_{ij}$ 则是第 $l$ 层的第 $i$ 个 `Feature Map` 在位置 $j$ 处的像素点的值。根据同样的定义，我们可以得到 $\vec{x}$ 在 `conv4_2` 处的 `Feature Map` $P^l$ ，`F` 和 `P` 分别表示 `目标图像` $\vec{x}$ 和 `内容图像` $\vec{p}$ 在卷积层输出的特征映射。

    <div align=center><img src="./static/风格迁移/content loss.jpg"/></div>

    有了损失函数的定义之后，我们便可以根据损失函数的值计算其关于 $F^l_{ij}$ 的梯度值，从而实现从后向前的梯度更新。

    <div align=center><img src="./static/风格迁移/content loss2.jpg"/></div>


### `图像风格损失计算：`

* 图像风格的损失计算和内容表示的损失计算不一样，不是直接进行特征映射的比较，而是通过计算 `Gram` 矩阵得到图像的风格，然后再进行比较图像的风格损失， `Gram` 的计算：（ `Gram` 矩阵可以更好地表示图像的风格）

    `Gram` 矩阵： `Gram` 矩阵就是每一层滤波后的 `feature map`, 后将其转置并相乘得到的矩阵，如下图所示。其实就是不同滤波器滤波结果 `feature map` 两两之间的相关性。譬如说，（如下图）某一层中有一个滤波器专门检测尖尖的塔顶这样的东西，另一个滤波器专门检测黑色。又有一个滤波器负责检测圆圆的东西，又有一个滤波器用来检测金黄色。对梵高的原图做 `Gram` 矩阵，谁的相关性会比较大呢？如上图所示，“尖尖的”和“黑色”总是一起出现的，它们的相关性比较高。而“圆圆的”和“金黄色”都是一起出现的，他们的相关性比较高。因此在风格转移的时候，其实也在风景图里去寻找这种“匹配”，将尖尖的渲染为黑色，将圆圆的渲染为金黄色。如果我们承认“图像的艺术风格就是其基本形状与色彩的组合方式” ，这样一个假设，那么 `Gram` 矩阵能够表征艺术风格就是理所当然的事情了:

    <div align=center><img height = 200 src="./static/风格迁移/gram1.jpg"/></div>

    <div align=center><img height = 350  src="./static/风格迁移/gram2.jpg"/></div>


    <div align=center><img src="./static/风格迁移/style loss.jpg"/></div>

    另外一点和内容表示不同的是，风格表示使用了每个block的第一个卷积来计算损失函数，作者认为这种方式得到的纹理特征更为光滑，因为仅仅使用底层Feature Map得到的图像较为精细但是比较粗糙，而高层得到的图像则含有更多的内容信息，损失了一些纹理信息，但他的材质更为光滑。所以，综合了所有层的样式表示的损失函数为：

    <div align=center><img src="./static/风格迁移/style loss2.jpg"/></div>

    其中 $E_l$ 是 $S_l$  的 Gram 矩阵 $A^l$ 和 $F^l$ 的Gram 矩阵 $G^l$ 的均方误差，$w_l$ 为每层的风格损失权重，$N_l$和$M_l$对应着特征映射的高和宽。

    <div align=center><img src="./static/风格迁移/style loss3.jpg"/></div>
        

    其梯度更新：

    <div align=center><img src="./static/风格迁移/style loss4.jpg"/></div>

### `总的损失计算`

* 总的损失计算如下：通过调整 $\alpha 和 \beta$ 这两个超参数的值我们可以设置生成的图像更偏向于 $\vec{p}$ 的内容还是 $\vec{x}$ 的风格。

    <div align=center><img src="./static/风格迁移/total loss.jpg"/></div>

$$其中 \frac{\partial L_{total}}{\partial \vec{x}} 的值用于更新输入图像 \vec{x} 的内容$$ 

* `为什么风格损失要用多层的损失加权求和，而内容损失只用第四层的损失？`

    [论文](https://arxiv.org/pdf/1508.06576v2.pdf) 中做了这样的实验，可以看出，层数增高的时候，内容重构图可变化性增加，具有更大的风格变化能力。而风格随着使用的层数越多，风格迁移的稳定性越强。

## `固定风格任意内容的快速风格迁移：`

* 传统风格迁移算法在生成一张图片是往往需要较长时间。主要是因为这种图像生成算法本质是一种“训练”的过程，计算量大且占用大量内存。那么一个很自然的想法就出现了：如果我们不把生成图片作为一个”训练“过程。而把生成图片作为一种计算的过程。在Johnson的论文中，他首次提出了快速风格迁移的概念。主要通过一个卷积神经网络来生成图片，并用VGG16来计算风格损失与内容损失。 之后通过梯度下降的方式更新图像生成网络的参数。具体如下图

* `快速迁移` 在 `普通迁移` 的基础上做了改进，添加了一个可供训练的图像转换网络，针对一种风格图像进行训练后可以将任意输入图像非常迅速的进行图像迁移学习，让该图像具有学习好的图像风格。

* `original：`
  
    <div align=center><img height =300 src="./static/风格迁移/original.png
    "/></div>

* `fast：`

    <div align=center><img height =265 src="./static/风格迁移/fast.jpg"/></div>

* 普通的风格迁移的输入是随机噪声，快速风格迁移的输入是一张图像经过转换网络 $f_w$ 的输出。另外一部分是使用 VGG16 网络中的相关卷积层去度量一张图像的内容损失和风格损失。

* 在图像转换网络中主要分为三个阶段，分别是图像降维部分、残差连接部分，和图像升维部分。

    * `1)图像降维部分：`主要通过三个卷积层来完成，将图像的尺寸从 `256*256` 降维到 `64*64`，并且将通道数从3个增加到128个特征映射。

    * `2)残差连接部分：`该部分是通过连接5个残差块，对图像进行学习，该结构用于学习如何在原图上添加少量内容，改变原图的风格，其中每个残差连接的结构如图所示：

        <div align=center><img height =200 src="./static/风格迁移/residual network.jpg"/></div>

        `残差连接：`通过将单元的输入直接与单元输出加在一起，然后再激活，通过这种方法计算，使得在前向传播的时候，输入信号可以从任意低层直接传播到高层。相当于包含了一个天然的恒等映射，一定程度上解决网络退化问题。

    * `3)图像的升维部分：`该部分主要输出5个残差单元，通过三个卷积层的操作，主键将其通道数从128降到3，每个特征映射的尺寸从 `64*64` 升到 `256*256` ，这一部分通过 `转置卷积` 来完成。




## `Reference：`

* `图像风格迁移详解：`https://zhuanlan.zhihu.com/p/55948352
  

* `Image Style Transfer：多风格 TensorFlow 实现：`https://www.cnblogs.com/subic/p/8110478.html

* `Image Style Transfer Using Convolutional Neural Networks：`https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf
# PR (Precision Recall) 曲线

`PR曲线` 展示的是 `Precision vs Recall` 的曲线，`PR曲线` 与 `ROC曲线` 的相同点是都采用了 `TPR (Recall)`，都可以用 `AUC` 来衡量分类器的效果。不同点是`ROC曲线` 使用了 `FPR` ，而 `PR曲线` 使用了 `Precision` ，因此 __PR曲线的两个指标都聚焦于正例__ 。

*   P-R 图直观地显示出学习器在样本总体上的 `查全率`、 `查准率`。

*   类别不平衡问题中由于主要关心正例，所以在此情况下PR曲线被广泛认为优于ROC曲线。

PR 曲线是以 Recall 为横轴，Precision 为纵轴；而 ROC曲线则是以 FPR 为横轴，TPR 为纵轴。__如下图所示__


<div align=center><img width="550" height="400" src="./static/pr2.png"/></div>


## 如何对比多个学习器的性能

__`在ROC空间，ROC曲线越凸向左上方向效果越好。与ROC曲线左上凸不同的是，PR曲线是右上凸效果越好。`__

`未发生交叉`：在进行比较时，若一个学习器的 P-R 曲线被另一个学习器的 P-R 曲线完全"包住" ，则可断言后者的性能优于前者,如 图中的学习器A和学习器C。

`发生交叉`：如果两个学习器的P - R曲线发生交叉，那么可以比较 P-R曲线下方的面积，但是不容易求，所以可以采用`“平衡点”`作为度量方法，它是`“查全率”`和`“查准率”`相等时的取值，如图中的学习器B的BEP为0.75，A为0.8，可以判断出学习器A优于学习器B。

但是BEP过于简化，更常用的是使用 `F1度量值`。

<div align=center><img src="./static/Performance_metrics/F1.png"/></div>

在一些应用中，`对查准率和查全率的重视程度不同`，可以采用F1度量的一般形式 --- `Fβ`

<div align=center><img src="./static/Performance_metrics/Fβ.png"/></div>

`β > 0`,度量了查全率对查准率的相对重要性，`β = 1` 时退化为标准的F1，`β > 1`时查全率有更大的影响，`β < 1`时，查准率有更大的影响。

## 使用场景

`ROC曲线由于兼顾正例与负例`，所以适用于评估分类器的整体性能，相比而言 `PR曲线完全聚焦于正例`。

如果有多份数据且存在不同的类别分布，比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候 :

* `roc曲线`：`如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合`，因为类别分布改变可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；

* `pr曲线`：`如果想测试不同类别分布下对分类器的性能的影响，则PR曲线比较适合`。

如果想要 __`评估在相同的类别分布下正例的预测情况`__，则宜选 __`PR曲线`__。

__`类别不平衡问题中`__ ，__`ROC曲线通常会给出一个乐观的效果估计`__，所以大部分时候还是 __`PR曲线更好`__。

最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1 score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。


#### 笔记参考链接：

-《[机器学习之类别不平衡问题 (2) —— ROC和PR曲线](https://zhuanlan.zhihu.com/p/34655990)》






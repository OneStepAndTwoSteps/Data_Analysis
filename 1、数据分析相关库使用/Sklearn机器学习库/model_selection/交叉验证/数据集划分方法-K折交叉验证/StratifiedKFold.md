# StratifiedKFold 

`Stratified [ˈstrætɪfaɪd]`

StratifiedKFold 用法类似Kfold，但是他是分层采样，确保训练集，测试集中各类别样本的比例与原始数据集中相同。

*   训练/测试集的划分要尽可能保持数据分布的一致性，避免 因数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中 至少要保持样本的类别比例相似

*   若 S(训练集)、 T(测试集) 中样本类别比例差别很大，则误差估计将由于训练/测试数据分布的差异 而产生偏差.

*   在不少问题中要求样本（数据）采样自同一个分布是因为希望用训练数据集训练得到的模型可以合理用于测试集，使用同分布假设能够使得这个做法解释得通。

*   （机器学习就是利用当前获取到的信息（或数据）进行训练学习，用以对未来的数据进行预测、模拟。因此需要我们使用的历史数据具有总体的代表性。）

## `分布不一致带来的偏差: ` 

比如我们有2000个二分类的样本，正类别和负类别各自1000个(1:1)。交叉验证分成5组。 我们使用KFold，运气不好的的时候，可能每组里样本的比例很不平均，比如第一组400个样本都是正例，第二组400个样本都是负例。这样我们把第一组用于验证，剩下的4组用于训练，则训练的1600个样本里有1000个负例，600个正例。由于类别分布发生的了很大的倾斜(3:5)，会导致训练的模型比较偏向于预测类别为负例，自然会影响模型最终的预测效果，也就是发生了偏差。

## `StratifiedKFold 案例:`

    #依照标签的比例来抽取数据，本案例集标签0和1的比例是1：1

    #因此在抽取数据时也是按照标签比例1：1来提取的

    import numpy as np
    from sklearn.model_selection import StratifiedKFold

    X=np.array([

    0    [1,2,3,4],
    1    [11,12,13,14], 
    2    [21,22,23,24], 
    3    [31,32,33,34], 
    4    [41,42,43,44], 
    5    [51,52,53,54], 
    6    [61,62,63,64], 
    7    [71,72,73,74]  

    ])

    y=np.array([1,1,0,0,1,1,0,0])


    sfolder = StratifiedKFold(n_splits=4,random_state=1)
    
    for train, test in sfolder.split(X,y):
    
        print('Train: %s | test: %s' % (train, test))

__out__

    Train: [1 3 4 5 6 7] | test: [0 2]  # 0对应上面的第0个样本-标签1 2对应上面的第2个样本-标签0

    Train: [0 2 4 5 6 7] | test: [1 3]

    Train: [0 1 2 3 5 7] | test: [4 6]

    Train: [0 1 2 3 4 6] | test: [5 7]


### 胡思乱想

StratifiedKFold有的时候可能不能完全精确的进行分层抽样，还和你 n_splits 的划分有关，比如你现在的 lable 比例是 6:2 = 3 : 1 ,那么你 n_splits 设置成 2，你可以进行3：1 的分层抽样，但是如果你的 lable 比例是 5：3 ，你 n_splits 设置成 2，最终分层后的lable 其实并不会是 5：3，拿下面的数据举例，一共八条， n_splits = 2，那你的 训练数据和测试数据的条数比例是 1：1：
    
    lable：[1,1,1,0,1,1,0,0]

    Train: [2 5 6 7] | test: [0 1 3 4]
    Train: [0 1 3 4] | test: [2 5 6 7]

此时 train 和 test 中标签为0和1的比例就不是 5：3


ps：如何计算test的条数：数据量/n_splits = test的条目，比如上面：8条数据/2 = 4,测试数据就4条。不过当数据量够大的时候基本可以精确分层
# `生成对抗网络：`


## `一、生成对抗网络介绍：`

* 生成对抗网络（Generative Adversarial Networks，简称GAN）是一种深度学习模型，由加州大学伯克利分校的Ian Goodfellow等人于2014年提出。GAN的主要思想是通过训练两个神经网络，一个生成器（Generator）和一个判别器（Discriminator），让它们在博弈中相互对抗、相互促进，最终达到训练出一个能够生成与真实数据相似的虚假数据的目的。

    具体来说，生成器的任务是将一个随机向量转化为一张与真实数据相似的图片或者其他类型的数据，而判别器的任务则是对于一张图片或者数据，判断它是真实数据还是生成器生成的虚假数据。在训练的过程中，生成器会尽可能地让自己生成的虚假数据被判别器识别为真实数据，而判别器则会尽可能地区分真实数据和虚假数据。

    这种博弈过程中，生成器和判别器不断地进行迭代训练，直到生成器生成的虚假数据和真实数据的分布越来越接近，判别器也越来越难以区分真实数据和虚假数据。最终，生成器可以生成非常逼真的虚假数据，可以被误认为是真实数据。GAN已经被成功地应用于图像生成、语音生成、文本生成等领域，取得了很好的效果。


## `二、对抗样本攻击：`


### `2.1、模型的攻击：`
  
* 对于模型的攻击我们一般把手段分为白盒攻击和黑盒攻击，白盒攻击（white-box attack）和黑盒攻击（black-box attack）是两种常见的模型攻击方式。它们的主要区别在于攻击者是否知道被攻击模型的内部结构和参数。

    * `白盒攻击：`指攻击者拥有被攻击模型的全部内部结构和参数的情况下进行攻击，也就是说攻击者对被攻击模型是有完全的了解的。在白盒攻击中，攻击者可以根据模型的内部结构和参数进行针对性的优化，使得攻击效果更好，攻击成功率更高。

    * `黑盒攻击：`则指攻击者没有被攻击模型的内部结构和参数信息，只能通过输入输出的方式进行攻击。在黑盒攻击中，攻击者需要通过不断的探测和尝试，获得足够多的关于被攻击模型的信息，从而逐步了解其内部结构和参数，以达到攻击的目的。

    * 需要注意的是，在实际场景中，攻击者通常无法获得被攻击模型的全部内部信息，因此大多数攻击都是黑盒攻击。

* `白盒攻击和黑盒攻击：`一般来说，需要利用模型的梯度信息来生成对抗样本的攻击方式，被认为是白盒攻击。这种攻击方式利用模型的内部信息，可以更加准确和有效地生成对抗样本，但是它也更容易被检测和防御。相反，不需要访问模型内部信息的攻击方式，比如只利用模型的输入输出结果来生成对抗样本的攻击方式，被认为是黑盒攻击。黑盒攻击的实现可能会更加困难，但是它具有更高的实用性和可移植性，因为它可以被用于攻击任何模型而不需要特定的知识。


### `2.2、文本的生成对抗攻击：`

* 传统的生成对抗样本的攻击算法比如：FGSM、 Greedy Attack based on perturbation、 Gumbel Attack based on scalable learning 等，但是这些攻击方式是属于白盒攻击。

* 为了实现黑盒攻击的效果以下算法被提出：DeepWord Bug algorithm、 token transformation method 、PWWS。





